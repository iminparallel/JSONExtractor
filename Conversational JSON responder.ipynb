{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "187689d9",
   "metadata": {},
   "source": [
    "#### Importing the API key and Instantiate the Model\n",
    "     Implemented:\n",
    "     1. Conversational Memory\n",
    "     2. Two Variations of JSON Extractor from queries\n",
    "     3. Time Context for llama to predict the dates correctly\n",
    "     4. Parses JSON with Pydantic Output Parser\n",
    "     5. Date Formatting\n",
    "     6. Limited Support for relative date ranges\n",
    "     7. Relative support for spelling mistakes\n",
    "     8. In case no date range is give, it accepts the last year \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3243522",
   "metadata": {},
   "source": [
    "##### Requirements\n",
    "    1. pip install llama-index-llms-groq\n",
    "    2. pip install torch\n",
    "    3. pip install langchain_groq\n",
    "    4. pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f900ba",
   "metadata": {},
   "source": [
    " Get the GROQ_API_KEY:</br>\n",
    "         export GROQ_API_KEY=[your-api-key-here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "75f53ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "## importing api key\n",
    "groq_api_key = os.environ['GROQ_API_KEY']\n",
    "\n",
    "# importing llama_inde\n",
    "from llama_index.llms.groq import Groq\n",
    "\n",
    "# instantiating the model\n",
    "llama3 = Groq(model=\"llama3-8b-8192\", \n",
    "              api_key=groq_api_key, \n",
    "              temperature=0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddbce1f",
   "metadata": {},
   "source": [
    "#### Defin JSON Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6aca688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List # to define a Json class\n",
    "from pydantic import BaseModel, Field ,ValidationError # pydantinc data parser\n",
    "from datetime import datetime\n",
    "\n",
    "class Entity(BaseModel):\n",
    "    #Class Representing Individual Entity\n",
    "\n",
    "    entity: Optional[str] = Field(description=\"Name of the Entity.\")\n",
    "    parameter: Optional[str] = Field(description=\"Parameter of the Entity.\")\n",
    "    start: Optional[datetime] = Field(description=\"Start Date of the Parameter.\")\n",
    "    end: Optional[datetime] = Field(description=\"End Date of the Parameter\")\n",
    "\n",
    "class Entities(BaseModel):\n",
    "    #Identifying information about all Entities in a text.\n",
    "\n",
    "    entities: List[Entity]   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d969e512",
   "metadata": {},
   "source": [
    "#### Generate Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ba854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser imports\n",
    "from llama_index.core.program import LLMTextCompletionProgram, FunctionCallingProgram\n",
    "from llama_index.core.output_parsers import PydanticOutputParser,ValidationError\n",
    "\n",
    "\n",
    "# giving a detailed prompt\n",
    "prompt_template_str = \"\"\"\\\n",
    "You are an expert data parser. Parse data from user query and store them in following fields.\n",
    "\n",
    "1. Entities (Company names mentioned in the query).\n",
    "2. Parameter (Performance metric requested, e.g., revenue, profit, etc. Should be same for all entities in a query).\n",
    "3. Start Date (Beginning of the requested Time period start for the metric requested. Should be same for all entities in a query).\n",
    "4. End Date (Ending of the requested Time period end for the metric requested. Should be same for all entities in a query).\n",
    "6. If the query mentions relative dates (e.g., \"last quarter\", \"previous month\"), convert these into exact calendar dates.\n",
    "7. If Period in not specified start date should be one year ago and end date should be today.\n",
    "If you don't know any field then set it to None.\n",
    "\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "# instantiating the parser\n",
    "pydantic_data_parser = LLMTextCompletionProgram.from_defaults(\n",
    "    output_parser=PydanticOutputParser(Entities),\n",
    "    #output_cls=Person,\n",
    "    prompt_template_str=prompt_template_str,\n",
    "    llm=llama3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513690f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask a question: compare to flipkart\n",
      "cound not understand, please be specific\n"
     ]
    }
   ],
   "source": [
    "# Building a Chat\n",
    "while True:\n",
    "    user_question = input(\"Ask a question: \")\n",
    "    if user_question:\n",
    "        try:\n",
    "            response = pydantic_data_parser(query=user_question)\n",
    "            dc = response.dict()\n",
    "\n",
    "            for entity in dc['entities']: ## converting date time formats\n",
    "                entity['start'] = entity['start'].strftime('%Y-%m-%d')\n",
    "                entity['end'] = entity['end'].strftime('%Y-%m-%d')\n",
    "            print(dc['entities'])\n",
    "        except:\n",
    "            print(\"cound not understand, please be specific\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8142c0b0",
   "metadata": {},
   "source": [
    "#### Making it into a complete app with Conversational Memory and Date Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd75db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I am your parser, What do you want to look into today? Please give a company name with a matric\n",
      "Ask a question: give amazon's profit\n",
      "Chatbot: [{'entity': 'Amazon', 'parameter': 'profit', 'start': '2023-12-09', 'end': '2024-12-09'}]\n",
      "Ask a question: compare it to flipkart\n",
      "Chatbot: [{'entity': 'Amazon', 'parameter': 'profit', 'start': '2023-12-09', 'end': '2024-12-09'}, {'entity': 'Flipkart', 'parameter': 'profit', 'start': '2023-12-09', 'end': '2024-12-09'}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain_groq import ChatGroq\n",
    "from typing import Optional, List # to define a Json class\n",
    "from pydantic import BaseModel, Field ,ValidationError # pydantinc data parser\n",
    "from datetime import datetime\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "date = datetime.today().strftime('%Y-%m-%d') # Storing Today's date\n",
    "\n",
    "def main():\n",
    "    # JSON Class\n",
    "    class Entity(BaseModel):\n",
    "        entity: Optional[str] = Field(description=\"Name of the Entity.\")\n",
    "        parameter: Optional[str] = Field(description=\"Parameter of the Entity.\")\n",
    "        start: Optional[datetime] = Field(description=\"Start Date of the Parameter.\")\n",
    "        end: Optional[datetime] = Field(description=\"End Date of the Parameter\")\n",
    "\n",
    "    class Entities(BaseModel):\n",
    "        entities: List[Entity] \n",
    "    # Instantiating the Model\n",
    "    groq_api_key = os.environ['GROQ_API_KEY']\n",
    "    model = 'llama3-8b-8192'\n",
    "    groq_chat = ChatGroq(\n",
    "            groq_api_key=groq_api_key, \n",
    "            model_name=model\n",
    "    )\n",
    "    #Instantiating the Parser\n",
    "    parser = PydanticOutputParser(pydantic_object=Entities)\n",
    "\n",
    "    \n",
    "    print(\"Hello! I am your parser, What do you want to look into today? Please give a company name with a matric\")\n",
    "    # Accomodating prompt to have two more input variables, today's date and the conversation history\n",
    "    system_prompt = '''\n",
    "            {chat_history}\n",
    "            You are an expert data parser. Parse data from user query and store them in following fields.\n",
    "\n",
    "            1. Entities (Company names mentioned in the query).\n",
    "            2. Parameter (Performance metric requested, e.g., revenue, profit, etc. Should be same for all entities in a query).\n",
    "            3. Start Date (Beginning of the requested Time period start for the metric requested. Should be same for all entities in a query).\n",
    "            4. End Date (Ending of the requested Time period end for the metric requested. Should be same for all entities in a query).\n",
    "            6. If the query mentions relative dates (e.g., \"last quarter\", \"previous month\"), convert these into exact calendar dates.\n",
    "            7. If Period in not specified start date should be one year ago and end date should be today. Today is {date}\n",
    "            If you don't know any field then set it to None.\n",
    "            Our question is \n",
    "            {human_input}\n",
    "            Format instructions:\n",
    "            {format_instructions}\n",
    "            '''  \n",
    "    # Defining The prompt template with the required inputs\n",
    "    prompt = PromptTemplate(\n",
    "            template=system_prompt,\n",
    "            input_variables=[\"human_input\",\"date\", \"chat_history\" ],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "            ) \n",
    "    # Defining the conversational memory\n",
    "    conversational_memory_length = 1000 \n",
    "    memory = ConversationBufferWindowMemory(k=conversational_memory_length, memory_key=\"chat_history\",  input_key=\"human_input\", return_messages=True)\n",
    "\n",
    "\n",
    "    while True:\n",
    "        query = input(\"Ask a question: \")\n",
    "\n",
    "        if query:\n",
    "            # Passing the input paramets in formatted prompts\n",
    "            _input = prompt.format_prompt(human_input=query, date = date, chat_history = memory)\n",
    "            # Passing parameters to the chain\n",
    "            conversation = LLMChain(\n",
    "                llm=groq_chat,  \n",
    "                prompt=prompt,  \n",
    "                verbose=False,   \n",
    "                memory=memory,  \n",
    "            )\n",
    "            \n",
    "            try:\n",
    "                # Try to get a response\n",
    "                response = conversation.predict(human_input=_input.to_string(), date = date)\n",
    "                output = parser.parse(response)\n",
    "                dc = output.dict()\n",
    "                for entity in dc['entities']: ## converting date time formats\n",
    "                    entity['start'] = entity['start'].strftime('%Y-%m-%d')\n",
    "                    entity['end'] = entity['end'].strftime('%Y-%m-%d')\n",
    "                print(\"Chatbot:\", dc['entities'])\n",
    "            except:\n",
    "                # Else throw Error\n",
    "                print(\"Ran into a problem while parsing, please try again\") \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb9559b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
